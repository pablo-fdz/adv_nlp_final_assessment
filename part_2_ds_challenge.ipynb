{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e6bfb6",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc153a5d",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 2: Data Scientist Challenge (3.5 points)\n",
    "\n",
    "- **Objective:** Explore different techniques to enhance model performance with limited  labeled data. You will be limited to 32 labeled examples in your task.  The rest can be viewed as unlabelled data. \n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. BERT Model with Limited Data (0.5 points):** Train a BERT-based model using only 32 labeled examples and assess its performance.\n",
    "  - **b. Dataset Augmentation (1 point):** Experiment with an automated technique to increase your dataset size **without using LLMs** (chatGPT / Mistral / Gemini / etc...). Evaluate the impact on model performance.\n",
    "  - **c. Zero-Shot Learning with LLM (0.5 points):** Apply a LLM (chatGPT/Claude/Mistral/Gemini/...) in a zero-shot learning setup. Document the performance.\n",
    "  - **d. Data Generation with LLM (1 point):** Use a LLM (chatGPT/Claude/Mistral/Gemini/...) to generate new, labeled  dataset points. Train your BERT model with it + the 32 labels. Analyze  how this impacts model metrics.\n",
    "  - **e. Optimal Technique Application (0.5 points):** Based on the previous experiments, apply the most effective  technique(s) to further improve your model's performance. Comment your results and propose improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d48a5",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e6d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b700f",
   "metadata": {},
   "source": [
    "## 0.3. Loading the data: Swiss Judgement Prediction\n",
    "\n",
    "Source: https://huggingface.co/datasets/rcds/swiss_judgment_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c4b4b",
   "metadata": {},
   "source": [
    "# 1. BERT Model with Limited Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaca434",
   "metadata": {},
   "source": [
    "# 2. Dataset Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ccf8a",
   "metadata": {},
   "source": [
    "# 3. Zero-Shot Learning with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb57e3",
   "metadata": {},
   "source": [
    "# 4. Data Generation with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ad1cc",
   "metadata": {},
   "source": [
    "# 5. Optimal Technique Application"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse-nlp-y6-47KiC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
