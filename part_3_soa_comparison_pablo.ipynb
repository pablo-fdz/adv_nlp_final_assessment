{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 3: State of the Art Comparison (2 points)\n",
    "\n",
    "- **Objective:** Benchmark your model against the SOA with the full dataset now available.\n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. Full Dataset Training (0.25 points):** Incrementally train your model with varying percentages of the full dataset (1%, 10%, 25%, 50%, 75%, and 100%). Record the results.\n",
    "  - **b. Learning Curve (0.25 points):** Plot a learning curve based on the training data percentages.\n",
    "  - **c. Technique Comparison (0.5 points):** Incorporate the techniques tested in Part 2 into your training schema for comparison.\n",
    "  - **d. Methodology Analysis (1 point):** Analyze and compare all methods employed. Discuss the effectiveness and limitations observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SpaCy model 'fr_core_news_sm' loaded successfully\n",
      "Downloading WordNet...\n",
      "Downloading Open Multilingual WordNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/pablo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pablo/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "2025-06-15 20:35:58.933747: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-15 20:35:58.942530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750012558.952632  470988 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750012558.955663  470988 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750012558.964880  470988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750012558.964895  470988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750012558.964896  470988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750012558.964897  470988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-15 20:35:58.968327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from library.utilities import set_seed, sample_balanced_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from library.incremental_train.doc import run_incremental_training, train_with_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specific for mac users with M1 chip (That do not have CUDA)\n",
    "# # !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# import torch\n",
    "# print(torch.backends.mps.is_available())      # Is Metal available?\n",
    "# print(torch.backends.mps.is_built()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect if MPS (GPU in Mac) is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch.ones(3, 3).to(device)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42. This ensures reproducibility of results across runs.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Full dataset training: Incrementally train your mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded DataFrame shape: (31094, 9)\n",
      "\n",
      "Loaded DataFrame schema:\n",
      "Schema({'id': Int32, 'year': Int32, 'text': String, 'labels': Int64, 'language': String, 'region': String, 'canton': String, 'legal area': String, 'split': String})\n",
      "\n",
      "First few rows of the loaded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>year</th><th>text</th><th>labels</th><th>language</th><th>region</th><th>canton</th><th>legal area</th><th>split</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>2000</td><td>&quot;A.- Par contrat d&#x27;entreprise s…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;civil law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>1</td><td>2000</td><td>&quot;A.- Le 12 avril 1995, A._ a su…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>2</td><td>2000</td><td>&quot;A.- En février 1994, M._ a été…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>3</td><td>2000</td><td>&quot;A.- M._ a travaillé en qualité…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>6</td><td>2000</td><td>&quot;A.- Le 29 septembre 1997, X._ …</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Espace Mittelland&quot;</td><td>&quot;ne&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────┬──────┬───────────────────┬────────┬───┬───────────────────┬────────┬───────────────┬───────┐\n",
       "│ id  ┆ year ┆ text              ┆ labels ┆ … ┆ region            ┆ canton ┆ legal area    ┆ split │\n",
       "│ --- ┆ ---  ┆ ---               ┆ ---    ┆   ┆ ---               ┆ ---    ┆ ---           ┆ ---   │\n",
       "│ i32 ┆ i32  ┆ str               ┆ i64    ┆   ┆ str               ┆ str    ┆ str           ┆ str   │\n",
       "╞═════╪══════╪═══════════════════╪════════╪═══╪═══════════════════╪════════╪═══════════════╪═══════╡\n",
       "│ 0   ┆ 2000 ┆ A.- Par contrat   ┆ 0      ┆ … ┆ null              ┆ null   ┆ civil law     ┆ train │\n",
       "│     ┆      ┆ d'entreprise s…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 1   ┆ 2000 ┆ A.- Le 12 avril   ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1995, A._ a su…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 2   ┆ 2000 ┆ A.- En février    ┆ 0      ┆ … ┆ Région lémanique  ┆ ge     ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1994, M._ a été…  ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 3   ┆ 2000 ┆ A.- M._ a         ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ travaillé en      ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ qualité…          ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 6   ┆ 2000 ┆ A.- Le 29         ┆ 0      ┆ … ┆ Espace Mittelland ┆ ne     ┆ penal law     ┆ train │\n",
       "│     ┆      ┆ septembre 1997,   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ X._ …             ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "└─────┴──────┴───────────────────┴────────┴───┴───────────────────┴────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Parquet file\n",
    "df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_combined.parquet')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"\\nLoaded DataFrame shape:\", df.shape)\n",
    "print(\"\\nLoaded DataFrame schema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nFirst few rows of the loaded DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training, validation and test sets\n",
    "train_df = df.filter(pl.col('split') == 'train')\n",
    "val_df = df.filter(pl.col('split') == 'validation')\n",
    "test_df = df.filter(pl.col('split') == 'test')\n",
    "\n",
    "# Delete the original data to free up memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the train, validation and test Parquet files\n",
    "# train_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_train.parquet')\n",
    "# valid_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_valid.parquet')\n",
    "# test_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_test.parquet')\n",
    "\n",
    "# # Display the loaded DataFrames\n",
    "# print(\"\\nTrain DataFrame shape:\", train_df.shape)\n",
    "# print(\"\\nValidation DataFrame shape:\", valid_df.shape)\n",
    "# print(\"\\nTest DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# print(\"\\nTrain DataFrame schema:\")\n",
    "# print(train_df.schema)\n",
    "# print(\"\\nFirst few rows of the train DataFrame:\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: almanach/camembert-base, Max Length: 512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"almanach/camembert-base\"  # Path to the pre-trained model\n",
    "num_labels = 2  # Number of labels for the classification task (in this case, binary classification)\n",
    "max_length = min(int(AutoModel.from_pretrained(model_name).config.max_position_embeddings), 512)  # Maximum length of the input sequences (truncation if larger than this). Set dynamically based on the chosen model.\n",
    "\n",
    "print(f\"Model: {model_name}, Max Length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = train_with_percentage(train_df, val_df, 10, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result25 = train_with_percentage(train_df, val_df, 25, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sampling with replacement for positive class (need 5294, have 5197)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2ef172404b4ae0992f17f5066c8251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39153c5ffa254b9596cf11115ae7db0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2317' max='3310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2317/3310 27:19 < 11:43, 1.41 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.794177</td>\n",
       "      <td>0.485945</td>\n",
       "      <td>0.385477</td>\n",
       "      <td>0.257216</td>\n",
       "      <td>0.768875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.646257</td>\n",
       "      <td>0.623263</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.760664</td>\n",
       "      <td>0.614540</td>\n",
       "      <td>0.398992</td>\n",
       "      <td>0.296407</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.846607</td>\n",
       "      <td>0.649111</td>\n",
       "      <td>0.410423</td>\n",
       "      <td>0.316848</td>\n",
       "      <td>0.582435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.849848</td>\n",
       "      <td>0.672375</td>\n",
       "      <td>0.401417</td>\n",
       "      <td>0.325359</td>\n",
       "      <td>0.523883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239100</td>\n",
       "      <td>1.258928</td>\n",
       "      <td>0.581583</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.284379</td>\n",
       "      <td>0.656394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>1.214160</td>\n",
       "      <td>0.623910</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.304776</td>\n",
       "      <td>0.619414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that, due to the class imbalance, we will have to do sampling with replacement\n",
    "# to get enough samples for the minority class\n",
    "result50 = train_with_percentage(train_df, val_df, 50, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sampling with replacement for positive class (need 7942, have 5197)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b303e6add1742b1ba55bd8cfcca5375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1397da16933b4ba9884519e5d8e397e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2982' max='4970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2982/4970 34:06 < 22:45, 1.46 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.590011</td>\n",
       "      <td>0.679806</td>\n",
       "      <td>0.386378</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.480740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.604952</td>\n",
       "      <td>0.708562</td>\n",
       "      <td>0.368347</td>\n",
       "      <td>0.337612</td>\n",
       "      <td>0.405239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.718164</td>\n",
       "      <td>0.663328</td>\n",
       "      <td>0.355995</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.443760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.835823</td>\n",
       "      <td>0.652342</td>\n",
       "      <td>0.364817</td>\n",
       "      <td>0.295694</td>\n",
       "      <td>0.476117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.867743</td>\n",
       "      <td>0.705008</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.406780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>1.084933</td>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.500770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that, due to the class imbalance, we will have to do sampling with replacement\n",
    "# to get enough samples for the minority class\n",
    "result75 = train_with_percentage(train_df, val_df, 75, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sampling with replacement for positive class (need 10589, have 5197)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6903ccaf8c9142ef92f5159a6fbf279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f437c3be24a34615a1b720ac96ab7e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3972' max='6620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3972/6620 44:58 < 29:59, 1.47 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.633844</td>\n",
       "      <td>0.656866</td>\n",
       "      <td>0.395216</td>\n",
       "      <td>0.313460</td>\n",
       "      <td>0.534669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.647722</td>\n",
       "      <td>0.693376</td>\n",
       "      <td>0.359217</td>\n",
       "      <td>0.319712</td>\n",
       "      <td>0.409861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.741087</td>\n",
       "      <td>0.682714</td>\n",
       "      <td>0.370513</td>\n",
       "      <td>0.317234</td>\n",
       "      <td>0.445300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.950179</td>\n",
       "      <td>0.666882</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.309761</td>\n",
       "      <td>0.479199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>1.031830</td>\n",
       "      <td>0.677221</td>\n",
       "      <td>0.361661</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.436055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.173391</td>\n",
       "      <td>0.663328</td>\n",
       "      <td>0.358374</td>\n",
       "      <td>0.298462</td>\n",
       "      <td>0.448382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that, due to the class imbalance, we will have to do sampling with replacement\n",
    "# to get enough samples for the minority class\n",
    "result100 = train_with_percentage(train_df, val_df, 100, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(summary_df, metric='eval_accuracy'):\n",
    "    \"\"\"\n",
    "    Plots a learning curve for the given metric from the summary DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=metric)\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve: {metric.replace(\"_\", \" \").title()} vs. Training Set Size')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(summary_df['percentage'])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy learning curve\n",
    "plot_learning_curve(summary_df, metric='eval_accuracy')\n",
    "\n",
    "# You can also plot F1, loss, etc.\n",
    "plot_learning_curve(summary_df, metric='eval_f1')\n",
    "plot_learning_curve(summary_df, metric='eval_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Technique Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from library.incremental_train.doc import run_incremental_training\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"almanach/camembert-base\",\n",
    "    \"dascim/juribert-base\",\n",
    "    \"google-bert/bert-base-multilingual-cased\"\n",
    "]\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train each model \n",
    "for model_name in model_names:\n",
    "    print(f\"\\nEntrenando modelo: {model_name}\")\n",
    "    summary_df = run_incremental_training(\n",
    "        train_df=train_df,\n",
    "        valid_df=val_df,\n",
    "        model_name=model_name,\n",
    "        max_length=max_length,\n",
    "        num_labels=num_labels,\n",
    "        seed=seed\n",
    "    )\n",
    "    results[model_name] = summary_df\n",
    "\n",
    "# Graph the learning curves\n",
    "def plot_comparison(results, metric='eval_accuracy'):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for model_name, summary_df in results.items():\n",
    "        plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=model_name.split('/')[-1])\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve Comparison: {metric.replace(\"_\", \" \").title()}')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([1, 10, 25, 50, 75, 100])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Comparison of accuracy and F1 scores\n",
    "plot_comparison(results, metric='eval_accuracy')\n",
    "plot_comparison(results, metric='eval_f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodology Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse-nlp-YMIcxN07-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
