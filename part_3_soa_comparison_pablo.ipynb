{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 3: State of the Art Comparison (2 points)\n",
    "\n",
    "- **Objective:** Benchmark your model against the SOA with the full dataset now available.\n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. Full Dataset Training (0.25 points):** Incrementally train your model with varying percentages of the full dataset (1%, 10%, 25%, 50%, 75%, and 100%). Record the results.\n",
    "  - **b. Learning Curve (0.25 points):** Plot a learning curve based on the training data percentages.\n",
    "  - **c. Technique Comparison (0.5 points):** Incorporate the techniques tested in Part 2 into your training schema for comparison.\n",
    "  - **d. Methodology Analysis (1 point):** Analyze and compare all methods employed. Discuss the effectiveness and limitations observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SpaCy model 'fr_core_news_sm' loaded successfully\n",
      "Downloading WordNet...\n",
      "Downloading Open Multilingual WordNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/pablo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pablo/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "2025-06-15 19:32:59.895636: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-15 19:32:59.904233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750008779.915095  419911 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750008779.918116  419911 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750008779.926944  419911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750008779.926959  419911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750008779.926960  419911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750008779.926962  419911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-15 19:32:59.930009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from library.utilities import set_seed, sample_balanced_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from library.incremental_train.doc import run_incremental_training, train_with_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specific for mac users with M1 chip (That do not have CUDA)\n",
    "# # !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# import torch\n",
    "# print(torch.backends.mps.is_available())      # Is Metal available?\n",
    "# print(torch.backends.mps.is_built()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect if MPS (GPU in Mac) is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch.ones(3, 3).to(device)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42. This ensures reproducibility of results across runs.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Full dataset training: Incrementally train your mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded DataFrame shape: (31094, 9)\n",
      "\n",
      "Loaded DataFrame schema:\n",
      "Schema({'id': Int32, 'year': Int32, 'text': String, 'labels': Int64, 'language': String, 'region': String, 'canton': String, 'legal area': String, 'split': String})\n",
      "\n",
      "First few rows of the loaded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>year</th><th>text</th><th>labels</th><th>language</th><th>region</th><th>canton</th><th>legal area</th><th>split</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>2000</td><td>&quot;A.- Par contrat d&#x27;entreprise s…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;civil law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>1</td><td>2000</td><td>&quot;A.- Le 12 avril 1995, A._ a su…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>2</td><td>2000</td><td>&quot;A.- En février 1994, M._ a été…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>3</td><td>2000</td><td>&quot;A.- M._ a travaillé en qualité…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>6</td><td>2000</td><td>&quot;A.- Le 29 septembre 1997, X._ …</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Espace Mittelland&quot;</td><td>&quot;ne&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────┬──────┬───────────────────┬────────┬───┬───────────────────┬────────┬───────────────┬───────┐\n",
       "│ id  ┆ year ┆ text              ┆ labels ┆ … ┆ region            ┆ canton ┆ legal area    ┆ split │\n",
       "│ --- ┆ ---  ┆ ---               ┆ ---    ┆   ┆ ---               ┆ ---    ┆ ---           ┆ ---   │\n",
       "│ i32 ┆ i32  ┆ str               ┆ i64    ┆   ┆ str               ┆ str    ┆ str           ┆ str   │\n",
       "╞═════╪══════╪═══════════════════╪════════╪═══╪═══════════════════╪════════╪═══════════════╪═══════╡\n",
       "│ 0   ┆ 2000 ┆ A.- Par contrat   ┆ 0      ┆ … ┆ null              ┆ null   ┆ civil law     ┆ train │\n",
       "│     ┆      ┆ d'entreprise s…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 1   ┆ 2000 ┆ A.- Le 12 avril   ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1995, A._ a su…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 2   ┆ 2000 ┆ A.- En février    ┆ 0      ┆ … ┆ Région lémanique  ┆ ge     ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1994, M._ a été…  ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 3   ┆ 2000 ┆ A.- M._ a         ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ travaillé en      ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ qualité…          ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 6   ┆ 2000 ┆ A.- Le 29         ┆ 0      ┆ … ┆ Espace Mittelland ┆ ne     ┆ penal law     ┆ train │\n",
       "│     ┆      ┆ septembre 1997,   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ X._ …             ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "└─────┴──────┴───────────────────┴────────┴───┴───────────────────┴────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Parquet file\n",
    "df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_combined.parquet')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"\\nLoaded DataFrame shape:\", df.shape)\n",
    "print(\"\\nLoaded DataFrame schema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nFirst few rows of the loaded DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training, validation and test sets\n",
    "train_df = df.filter(pl.col('split') == 'train')\n",
    "val_df = df.filter(pl.col('split') == 'validation')\n",
    "test_df = df.filter(pl.col('split') == 'test')\n",
    "\n",
    "# Delete the original data to free up memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the train, validation and test Parquet files\n",
    "# train_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_train.parquet')\n",
    "# valid_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_valid.parquet')\n",
    "# test_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_test.parquet')\n",
    "\n",
    "# # Display the loaded DataFrames\n",
    "# print(\"\\nTrain DataFrame shape:\", train_df.shape)\n",
    "# print(\"\\nValidation DataFrame shape:\", valid_df.shape)\n",
    "# print(\"\\nTest DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# print(\"\\nTrain DataFrame schema:\")\n",
    "# print(train_df.schema)\n",
    "# print(\"\\nFirst few rows of the train DataFrame:\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: almanach/camembert-base, Max Length: 512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"almanach/camembert-base\"  # Path to the pre-trained model\n",
    "num_labels = 2  # Number of labels for the classification task (in this case, binary classification)\n",
    "max_length = min(int(AutoModel.from_pretrained(model_name).config.max_position_embeddings), 512)  # Maximum length of the input sequences (truncation if larger than this). Set dynamically based on the chosen model.\n",
    "\n",
    "print(f\"Model: {model_name}, Max Length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = train_with_percentage(train_df, val_df, 10, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result25 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, due to the class imbalance, we will have to do sampling with replacement\n",
    "# to get enough samples for the minority class\n",
    "result50 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result75 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 1% of the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96d375e23d54216820679e16e91358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606d595e1be4497180824d9096ee4a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [119/140 06:36 < 01:11, 0.30 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673184</td>\n",
       "      <td>0.787399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701540</td>\n",
       "      <td>0.317932</td>\n",
       "      <td>0.351459</td>\n",
       "      <td>0.219493</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697207</td>\n",
       "      <td>0.438449</td>\n",
       "      <td>0.340167</td>\n",
       "      <td>0.225693</td>\n",
       "      <td>0.690293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722294</td>\n",
       "      <td>0.253958</td>\n",
       "      <td>0.347924</td>\n",
       "      <td>0.213001</td>\n",
       "      <td>0.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717870</td>\n",
       "      <td>0.312439</td>\n",
       "      <td>0.348039</td>\n",
       "      <td>0.217208</td>\n",
       "      <td>0.875193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673108</td>\n",
       "      <td>0.654281</td>\n",
       "      <td>0.244350</td>\n",
       "      <td>0.225554</td>\n",
       "      <td>0.266564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672467</td>\n",
       "      <td>0.634249</td>\n",
       "      <td>0.272494</td>\n",
       "      <td>0.233738</td>\n",
       "      <td>0.326656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.657576</td>\n",
       "      <td>0.685299</td>\n",
       "      <td>0.223285</td>\n",
       "      <td>0.231405</td>\n",
       "      <td>0.215716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.677178</td>\n",
       "      <td>0.590630</td>\n",
       "      <td>0.304992</td>\n",
       "      <td>0.236797</td>\n",
       "      <td>0.428351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.699906</td>\n",
       "      <td>0.494669</td>\n",
       "      <td>0.328179</td>\n",
       "      <td>0.227516</td>\n",
       "      <td>0.588598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.704552</td>\n",
       "      <td>0.490792</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.232853</td>\n",
       "      <td>0.622496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.632334</td>\n",
       "      <td>0.670436</td>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.228404</td>\n",
       "      <td>0.240370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.606785</td>\n",
       "      <td>0.282852</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.681200</td>\n",
       "      <td>0.713769</td>\n",
       "      <td>0.476252</td>\n",
       "      <td>0.330442</td>\n",
       "      <td>0.225734</td>\n",
       "      <td>0.616333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.704411</td>\n",
       "      <td>0.504685</td>\n",
       "      <td>0.332026</td>\n",
       "      <td>0.231470</td>\n",
       "      <td>0.587057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.644510</td>\n",
       "      <td>0.617447</td>\n",
       "      <td>0.277167</td>\n",
       "      <td>0.229525</td>\n",
       "      <td>0.349769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.642356</td>\n",
       "      <td>0.624233</td>\n",
       "      <td>0.279876</td>\n",
       "      <td>0.233954</td>\n",
       "      <td>0.348228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best metrics for 1% of data:\n",
      "shape: (1, 18)\n",
      "┌───────────┬───────────┬──────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ eval_loss ┆ eval_accu ┆ eval_f1  ┆ eval_prec ┆ … ┆ train_sam ┆ train_ste ┆ total_flo ┆ train_los │\n",
      "│ ---       ┆ racy      ┆ ---      ┆ ision     ┆   ┆ ples_per_ ┆ ps_per_se ┆ s         ┆ s         │\n",
      "│ f64       ┆ ---       ┆ f64      ┆ ---       ┆   ┆ second    ┆ cond      ┆ ---       ┆ ---       │\n",
      "│           ┆ f64       ┆          ┆ f64       ┆   ┆ ---       ┆ ---       ┆ f64       ┆ f64       │\n",
      "│           ┆           ┆          ┆           ┆   ┆ f64       ┆ f64       ┆           ┆           │\n",
      "╞═══════════╪═══════════╪══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 0.632334  ┆ 0.670436  ┆ 0.234234 ┆ 0.228404  ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
      "└───────────┴───────────┴──────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "\n",
      "Training with 10% of the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803c4bcd65c4a23ac80d3ab8a2f8a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2dbb09f1d646d58d37f5fe9cd19ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='603' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 603/1340 09:14 < 11:20, 1.08 it/s, Epoch 9/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695500</td>\n",
       "      <td>0.704335</td>\n",
       "      <td>0.394184</td>\n",
       "      <td>0.367195</td>\n",
       "      <td>0.235091</td>\n",
       "      <td>0.838213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.656064</td>\n",
       "      <td>0.666882</td>\n",
       "      <td>0.263045</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.283513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.625096</td>\n",
       "      <td>0.644911</td>\n",
       "      <td>0.371641</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.500770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.613500</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>0.707593</td>\n",
       "      <td>0.386441</td>\n",
       "      <td>0.345036</td>\n",
       "      <td>0.439137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.626186</td>\n",
       "      <td>0.673021</td>\n",
       "      <td>0.396901</td>\n",
       "      <td>0.323615</td>\n",
       "      <td>0.513097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.740511</td>\n",
       "      <td>0.620355</td>\n",
       "      <td>0.400816</td>\n",
       "      <td>0.299543</td>\n",
       "      <td>0.605547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.341400</td>\n",
       "      <td>1.015419</td>\n",
       "      <td>0.518578</td>\n",
       "      <td>0.392333</td>\n",
       "      <td>0.266778</td>\n",
       "      <td>0.741140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>1.218639</td>\n",
       "      <td>0.498546</td>\n",
       "      <td>0.386076</td>\n",
       "      <td>0.259713</td>\n",
       "      <td>0.751926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>1.066191</td>\n",
       "      <td>0.583845</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.282801</td>\n",
       "      <td>0.640986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best metrics for 10% of data:\n",
      "shape: (1, 18)\n",
      "┌──────┬───────────┬─────────────┬───────┬───┬─────────────┬─────────────┬────────────┬────────────┐\n",
      "│ loss ┆ grad_norm ┆ learning_ra ┆ epoch ┆ … ┆ train_sampl ┆ train_steps ┆ total_flos ┆ train_loss │\n",
      "│ ---  ┆ ---       ┆ te          ┆ ---   ┆   ┆ es_per_seco ┆ _per_second ┆ ---        ┆ ---        │\n",
      "│ f64  ┆ f64       ┆ ---         ┆ f64   ┆   ┆ nd          ┆ ---         ┆ f64        ┆ f64        │\n",
      "│      ┆           ┆ f64         ┆       ┆   ┆ ---         ┆ f64         ┆            ┆            │\n",
      "│      ┆           ┆             ┆       ┆   ┆ f64         ┆             ┆            ┆            │\n",
      "╞══════╪═══════════╪═════════════╪═══════╪═══╪═════════════╪═════════════╪════════════╪════════════╡\n",
      "│ null ┆ null      ┆ null        ┆ 4.0   ┆ … ┆ null        ┆ null        ┆ null       ┆ null       │\n",
      "└──────┴───────────┴─────────────┴───────┴───┴─────────────┴─────────────┴────────────┴────────────┘\n",
      "\n",
      "Training with 25% of the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa04fe78f234b97ab52295054b1af04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5294 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e88c155e71944eba52b41c6650fba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1328' max='3320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1328/3320 16:51 < 25:19, 1.31 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.683800</td>\n",
       "      <td>0.693649</td>\n",
       "      <td>0.556704</td>\n",
       "      <td>0.326791</td>\n",
       "      <td>0.239741</td>\n",
       "      <td>0.513097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661100</td>\n",
       "      <td>0.735433</td>\n",
       "      <td>0.488853</td>\n",
       "      <td>0.379608</td>\n",
       "      <td>0.254603</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.577443</td>\n",
       "      <td>0.685299</td>\n",
       "      <td>0.383544</td>\n",
       "      <td>0.325456</td>\n",
       "      <td>0.466872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.627165</td>\n",
       "      <td>0.679160</td>\n",
       "      <td>0.391917</td>\n",
       "      <td>0.325203</td>\n",
       "      <td>0.493066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.696368</td>\n",
       "      <td>0.665590</td>\n",
       "      <td>0.399304</td>\n",
       "      <td>0.320298</td>\n",
       "      <td>0.530046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.822210</td>\n",
       "      <td>0.631987</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.305246</td>\n",
       "      <td>0.591680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.849376</td>\n",
       "      <td>0.658158</td>\n",
       "      <td>0.370238</td>\n",
       "      <td>0.301649</td>\n",
       "      <td>0.479199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.265800</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.652342</td>\n",
       "      <td>0.401557</td>\n",
       "      <td>0.314186</td>\n",
       "      <td>0.556240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best metrics for 25% of data:\n",
      "shape: (1, 18)\n",
      "┌──────┬───────────┬─────────────┬───────┬───┬─────────────┬─────────────┬────────────┬────────────┐\n",
      "│ loss ┆ grad_norm ┆ learning_ra ┆ epoch ┆ … ┆ train_sampl ┆ train_steps ┆ total_flos ┆ train_loss │\n",
      "│ ---  ┆ ---       ┆ te          ┆ ---   ┆   ┆ es_per_seco ┆ _per_second ┆ ---        ┆ ---        │\n",
      "│ f64  ┆ f64       ┆ ---         ┆ f64   ┆   ┆ nd          ┆ ---         ┆ f64        ┆ f64        │\n",
      "│      ┆           ┆ f64         ┆       ┆   ┆ ---         ┆ f64         ┆            ┆            │\n",
      "│      ┆           ┆             ┆       ┆   ┆ f64         ┆             ┆            ┆            │\n",
      "╞══════╪═══════════╪═════════════╪═══════╪═══╪═════════════╪═════════════╪════════════╪════════════╡\n",
      "│ null ┆ null      ┆ null        ┆ 3.0   ┆ … ┆ null        ┆ null        ┆ null       ┆ null       │\n",
      "└──────┴───────────┴─────────────┴───────┴───┴─────────────┴─────────────┴────────────┴────────────┘\n",
      "\n",
      "Training with 50% of the data...\n"
     ]
    },
    {
     "ename": "ShapeError",
     "evalue": "cannot take a larger sample than the total population when `with_replacement=false`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mShapeError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_419911/1578788899.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train all the percentages incrementally:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m summary_df = run_incremental_training(\n\u001b[32m      3\u001b[39m     train_df=train_df,\n\u001b[32m      4\u001b[39m     valid_df=val_df,\n\u001b[32m      5\u001b[39m     model_name=model_name,\n",
      "\u001b[32m/media/pablo/Shared files/GDrive personal/BSE - DSDM/3-Advanced_Methods_in_NLP/Final assessment/adv_nlp_final_assessment/library/incremental_train/doc.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(train_df, valid_df, model_name, max_length, num_labels, seed)\u001b[39m\n\u001b[32m     96\u001b[39m     percentages = [\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m25\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m75\u001b[39m, \u001b[32m100\u001b[39m]\n\u001b[32m     97\u001b[39m     all_results = []\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pct \u001b[38;5;28;01min\u001b[39;00m percentages:\n\u001b[32m     99\u001b[39m         print(f\"\\nTraining with {pct}% of the data...\")\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         result = train_with_percentage(train_df, valid_df, pct, model_name, max_length, num_labels, seed)\n\u001b[32m    101\u001b[39m         all_results.append(result)\n\u001b[32m    102\u001b[39m         print(f\"\\nBest metrics for {pct}% of data:\")\n\u001b[32m    103\u001b[39m         print(result[\u001b[33m'best_epoch'\u001b[39m])\n",
      "\u001b[32m/media/pablo/Shared files/GDrive personal/BSE - DSDM/3-Advanced_Methods_in_NLP/Final assessment/adv_nlp_final_assessment/library/incremental_train/doc.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(train_df, valid_df, percentage, model_name, max_length, num_labels, seed)\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Use balanced sampling instead of random sampling\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# We convert the Polars Data Frame to an arrow Dataset and get a sample of the training data\u001b[39;00m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'labels'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m train_df.columns:\n\u001b[32m     30\u001b[39m         train_df = train_df.rename({\u001b[33m'labels'\u001b[39m: \u001b[33m'label'\u001b[39m})  \u001b[38;5;66;03m# Rename 'labels' to 'label' for compatibility with sampling function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     train_subset = sample_balanced_dataset(train_df, n_samples, seed)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'label'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m train_subset.column_names:\n\u001b[32m     33\u001b[39m         train_subset = train_subset.rename_column(\u001b[33m'label'\u001b[39m, \u001b[33m'labels'\u001b[39m)  \u001b[38;5;66;03m# Rename the label column again to 'labels' for compatibility with Hugging Face Trainer\u001b[39;00m\n\u001b[32m     34\u001b[39m     val_set = Dataset.from_polars(valid_df.select([\u001b[33m'text'\u001b[39m, \u001b[33m'labels'\u001b[39m]))\n",
      "\u001b[32m/media/pablo/Shared files/GDrive personal/BSE - DSDM/3-Advanced_Methods_in_NLP/Final assessment/adv_nlp_final_assessment/library/utilities/sample_balanced_dataset.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(dataset, num_samples, seed, sample_proportion)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Sample equal numbers from each class\u001b[39;00m\n\u001b[32m     32\u001b[39m     samples_per_class = num_samples // denominator\n\u001b[32m     33\u001b[39m \n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         pos_sampled = pos_examples.sample(n=samples_per_class, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, seed=seed)\n\u001b[32m     36\u001b[39m         neg_sampled = neg_examples.sample(n=samples_per_class, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, seed=seed)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Seed must be provided for reproducibility.\"\u001b[39m)\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/bse-nlp-YMIcxN07-py3.12/lib/python3.12/site-packages/polars/dataframe/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, n, fraction, with_replacement, shuffle, seed)\u001b[39m\n\u001b[32m  10830\u001b[39m \n\u001b[32m  10831\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(n, pl.Series):\n\u001b[32m  10832\u001b[39m             n = pl.Series(\u001b[33m\"\"\u001b[39m, [n])\n\u001b[32m  10833\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10834\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._from_pydf(self._df.sample_n(n._s, with_replacement, shuffle, seed))\n",
      "\u001b[31mShapeError\u001b[39m: cannot take a larger sample than the total population when `with_replacement=false`"
     ]
    }
   ],
   "source": [
    "# Train all the percentages incrementally:\n",
    "summary_df = run_incremental_training(\n",
    "    train_df=train_df,\n",
    "    valid_df=val_df,  \n",
    "    model_name=model_name,\n",
    "    max_length=max_length,\n",
    "    num_labels=num_labels,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(\"\\nFinal summary of results across all percentages:\")\n",
    "display(summary_df)\n",
    "\n",
    "\n",
    "# Or to train specific percentage only:\n",
    "# result = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(summary_df, metric='eval_accuracy'):\n",
    "    \"\"\"\n",
    "    Plots a learning curve for the given metric from the summary DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=metric)\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve: {metric.replace(\"_\", \" \").title()} vs. Training Set Size')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(summary_df['percentage'])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy learning curve\n",
    "plot_learning_curve(summary_df, metric='eval_accuracy')\n",
    "\n",
    "# You can also plot F1, loss, etc.\n",
    "plot_learning_curve(summary_df, metric='eval_f1')\n",
    "plot_learning_curve(summary_df, metric='eval_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Technique Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from library.incremental_train.doc import run_incremental_training\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"almanach/camembert-base\",\n",
    "    \"dascim/juribert-base\",\n",
    "    \"google-bert/bert-base-multilingual-cased\"\n",
    "]\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train each model \n",
    "for model_name in model_names:\n",
    "    print(f\"\\nEntrenando modelo: {model_name}\")\n",
    "    summary_df = run_incremental_training(\n",
    "        train_df=train_df,\n",
    "        valid_df=val_df,\n",
    "        model_name=model_name,\n",
    "        max_length=max_length,\n",
    "        num_labels=num_labels,\n",
    "        seed=seed\n",
    "    )\n",
    "    results[model_name] = summary_df\n",
    "\n",
    "# Graph the learning curves\n",
    "def plot_comparison(results, metric='eval_accuracy'):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for model_name, summary_df in results.items():\n",
    "        plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=model_name.split('/')[-1])\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve Comparison: {metric.replace(\"_\", \" \").title()}')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([1, 10, 25, 50, 75, 100])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Comparison of accuracy and F1 scores\n",
    "plot_comparison(results, metric='eval_accuracy')\n",
    "plot_comparison(results, metric='eval_f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodology Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse-nlp-YMIcxN07-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
