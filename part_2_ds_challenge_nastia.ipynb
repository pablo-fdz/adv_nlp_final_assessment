{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e6bfb6",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc153a5d",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 2: Data Scientist Challenge (3.5 points)\n",
    "\n",
    "- **Objective:** Explore different techniques to enhance model performance with limited  labeled data. You will be limited to 32 labeled examples in your task.  The rest can be viewed as unlabelled data. \n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. BERT Model with Limited Data (0.5 points):** Train a BERT-based model using only 32 labeled examples and assess its performance.\n",
    "  - **b. Dataset Augmentation (1 point):** Experiment with an automated technique to increase your dataset size **without using LLMs** (chatGPT / Mistral / Gemini / etc...). Evaluate the impact on model performance.\n",
    "  - **c. Zero-Shot Learning with LLM (0.5 points):** Apply a LLM (chatGPT/Claude/Mistral/Gemini/...) in a zero-shot learning setup. Document the performance.\n",
    "  - **d. Data Generation with LLM (1 point):** Use a LLM (chatGPT/Claude/Mistral/Gemini/...) to generate new, labeled  dataset points. Train your BERT model with it + the 32 labels. Analyze  how this impacts model metrics.\n",
    "  - **e. Optimal Technique Application (0.5 points):** Based on the previous experiments, apply the most effective  technique(s) to further improve your model's performance. Comment your results and propose improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d48a5",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f98abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars  # Install polars for faster data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e6d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "import polars as pl\n",
    "from library.metrics import Metrics\n",
    "from library.utilities import set_seed\n",
    "import torch \n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3dda6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3590, 0.7035, 0.4713],\n",
      "        [0.6689, 0.1912, 0.9507],\n",
      "        [0.7940, 0.2419, 0.0603],\n",
      "        [0.7771, 0.2834, 0.9313],\n",
      "        [0.1609, 0.7976, 0.7314]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b10671",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.version.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570741d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the metrics object to save the results\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f7babdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the availability of a GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280eac7",
   "metadata": {},
   "source": [
    "## 0.3. Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a2aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42. This ensures reproducibility of results across runs.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b700f",
   "metadata": {},
   "source": [
    "## 0.4. Loading the data: Swiss Judgement Prediction\n",
    "\n",
    "Source: https://huggingface.co/datasets/rcds/swiss_judgment_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ea67e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded DataFrame shape: (35386, 9)\n",
      "\n",
      "Loaded DataFrame schema:\n",
      "Schema({'id': Int32, 'year': Int32, 'text': String, 'label': Int64, 'language': String, 'region': String, 'canton': String, 'legal area': String, 'split': String})\n",
      "\n",
      "First few rows of the loaded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>year</th><th>text</th><th>label</th><th>language</th><th>region</th><th>canton</th><th>legal area</th><th>split</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>22014</td><td>2011</td><td>&quot;Faits: A. Le 28 octobre 2002 à…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;civil law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>11593</td><td>2007</td><td>&quot;Faits : Faits : A. Le 17 avril…</td><td>1</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>26670</td><td>2013</td><td>&quot;Faits: A. Par jugement du 2 ma…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;vd&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>5864</td><td>2004</td><td>&quot;Faits: Faits: A. N._, née en 1…</td><td>1</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;vd&quot;</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>16122</td><td>2009</td><td>&quot;Faits: A. Y._ est propriétaire…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;public law&quot;</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌───────┬──────┬───────────────────┬───────┬───┬──────────────────┬────────┬───────────────┬───────┐\n",
       "│ id    ┆ year ┆ text              ┆ label ┆ … ┆ region           ┆ canton ┆ legal area    ┆ split │\n",
       "│ ---   ┆ ---  ┆ ---               ┆ ---   ┆   ┆ ---              ┆ ---    ┆ ---           ┆ ---   │\n",
       "│ i32   ┆ i32  ┆ str               ┆ i64   ┆   ┆ str              ┆ str    ┆ str           ┆ str   │\n",
       "╞═══════╪══════╪═══════════════════╪═══════╪═══╪══════════════════╪════════╪═══════════════╪═══════╡\n",
       "│ 22014 ┆ 2011 ┆ Faits: A. Le 28   ┆ 0     ┆ … ┆ Région lémanique ┆ ge     ┆ civil law     ┆ train │\n",
       "│       ┆      ┆ octobre 2002 à…   ┆       ┆   ┆                  ┆        ┆               ┆       │\n",
       "│ 11593 ┆ 2007 ┆ Faits : Faits :   ┆ 1     ┆ … ┆ Région lémanique ┆ ge     ┆ penal law     ┆ train │\n",
       "│       ┆      ┆ A. Le 17 avril…   ┆       ┆   ┆                  ┆        ┆               ┆       │\n",
       "│ 26670 ┆ 2013 ┆ Faits: A. Par     ┆ 0     ┆ … ┆ Région lémanique ┆ vd     ┆ penal law     ┆ train │\n",
       "│       ┆      ┆ jugement du 2 ma… ┆       ┆   ┆                  ┆        ┆               ┆       │\n",
       "│ 5864  ┆ 2004 ┆ Faits: Faits: A.  ┆ 1     ┆ … ┆ Région lémanique ┆ vd     ┆ insurance law ┆ train │\n",
       "│       ┆      ┆ N._, née en 1…    ┆       ┆   ┆                  ┆        ┆               ┆       │\n",
       "│ 16122 ┆ 2009 ┆ Faits: A. Y._ est ┆ 0     ┆ … ┆ Région lémanique ┆ ge     ┆ public law    ┆ train │\n",
       "│       ┆      ┆ propriétaire…     ┆       ┆   ┆                  ┆        ┆               ┆       │\n",
       "└───────┴──────┴───────────────────┴───────┴───┴──────────────────┴────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Parquet file\n",
    "df = pl.read_parquet('swiss_judgment_prediction_fr&it_clean.parquet')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"\\nLoaded DataFrame shape:\", df.shape)\n",
    "print(\"\\nLoaded DataFrame schema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nFirst few rows of the loaded DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64b0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_texts = df.filter((pl.col('language') == 'fr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c4b4b",
   "metadata": {},
   "source": [
    "# 1. BERT Model with Limited Data\n",
    "\n",
    "Outline of the intermediate tasks:\n",
    "\n",
    "1. Preprocessing Pipeline\n",
    "   - Lowercasing, punctuation stripping (or not, depending on BERT tokenizer).\n",
    "   - Sentencepiece/BPE tokenization via the CamemBERT (for French) or UmBERTo (for Italian).\n",
    "   - (Optional) language tags if you merge FR+IT in one model.\n",
    "2. Hold-out Split. Since you only have 32 labels: use stratified k-fold CV (e.g. 8 × 4-fold) to get reliable estimates, or leave-one-out if you want maximum training data per fold.\n",
    "3. BERT Model with Only 32 Examples\n",
    "   - Model Choice: Pick a multilingual BERT (mBERT) or separate CamemBERT/UmBERTo checkpoint. Alternatives:\n",
    "     - Multilingual/monolingual models:\n",
    "       -  [BERT multilingual base model (cased)](https://huggingface.co/google-bert/bert-base-multilingual-cased). Paper: \"[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\". \n",
    "       -  [CamemBERT 2.0](https://huggingface.co/almanach/camembertv2-base) and [CamemBERTav2](https://huggingface.co/almanach/camembertav2-base), models trained with French text and explained in the paper: [CamemBERT 2.0: A Smarter French Language Model Aged to Perfection](https://arxiv.org/html/2411.08868v1#S3). These models supposedly improve over the performance of the original [CamemBERT](https://huggingface.co/docs/transformers/en/model_doc/camembert) model, explained in \"[CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894)\".\n",
    "       -  [FlauBERT](https://huggingface.co/docs/transformers/en/model_doc/flaubert), another model pre-trained on French text. Paper: \"[FlauBERT: Unsupervised Language Model Pre-training for French](https://arxiv.org/abs/1912.05372)\". \n",
    "       -  [BERT Base Italian Uncased](https://huggingface.co/dbmdz/bert-base-italian-uncased), [Cased](https://huggingface.co/dbmdz/bert-base-italian-cased),and [XXL Uncased](https://huggingface.co/dbmdz/bert-base-italian-xxl-uncased). \n",
    "       -  [UmBERTo Commoncrawl Cased](https://huggingface.co/Musixmatch/umberto-commoncrawl-cased-v1), another model trained with a large corpus of texts in Italian.\n",
    "      -  Domain-specific models (law):\n",
    "          - [LEGAL-BERT](https://huggingface.co/nlpaueb/legal-bert-base-uncased) does not seem to be a good option as it was trained only on English data.\n",
    "          - [JuriBERT](https://huggingface.co/dascim/juribert-base) for legal texts in French. Paper explaining the model: [JuriBERT: A Masked-Language Model Adaptation for French Legal Text](https://arxiv.org/pdf/2110.01485).\n",
    "          - [ITALIAN-LEGAL-BERT](https://huggingface.co/dlicari/Italian-Legal-BERT) for legal text in Italian. Paper explaining the model: [ITALIAN-LEGAL-BERT models for improving natural language processing tasks in the Italian legal domain](https://www.sciencedirect.com/science/article/pii/S0267364923001188).\n",
    "   - Fine-tuning Setup.\n",
    "     - Freeze or unfreeze last n encoder layers—try both.\n",
    "     - Small learning rate (2e-5 – 5e-5), batch size = 8 or 16.\n",
    "     - Early stopping on validation loss.\n",
    "4. Training & Evaluation\n",
    "    - Run your k-fold CV training loops.\n",
    "    - Track accuracy, F1, precision, recall per fold.\n",
    "    - Report mean ± std.\n",
    "5. Error Analysis and feature interpretation.\n",
    "    - Use `LIME` for analyzing the most relevant features for classifying the texts. \n",
    "    - Look at which examples are mispredicted.\n",
    "    - Check language breakdown (FR vs. IT) to see if one is harder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831052f",
   "metadata": {},
   "source": [
    "## 1.1. Standard fine-tuning\n",
    "\n",
    "Notebook of reference: `Session_5_1_BERT_HF_Implementation.ipynb`, sections 1, 2 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e98272",
   "metadata": {},
   "source": [
    "## 1.2. Using SetFit (\"Sentence Transformer Fine-Tuning\")\n",
    "\n",
    "Notebook of reference: `Session_6_2_Zero_Shot_Classification.ipynb`, introduction, step 1 (loading data) and step 6 (\"Few-Shot Classification with SetFit\").\n",
    "\n",
    "Applying SetFit (the “Sentence Transformer Fine-Tuning” recipe) absolutely counts as **training** (it fine-tunes a pre-trained sentence-embedding model, plus fits a small classifier on top). And indeed, SetFit was built **for** the exactly your scenario—getting strong performance with as few as a few dozen labeled examples.\n",
    "\n",
    "---\n",
    "\n",
    "**Why SetFit = Training**\n",
    "\n",
    "* **Contrastive fine-tuning:**\n",
    "  You start with a frozen (or lightly unfrozen) Sentence-Transformer model and then *fine-tune* it on automatically generated sentence pairs derived from your 32 labels.\n",
    "* **Classifier head training:**\n",
    "  After contrastive tuning, you fit a lightweight logistic-regression (or small MLP) classifier on the resulting embeddings.\n",
    "* Both steps update model parameters—so it’s training/fine-tuning, not mere prompt-engineering or zero-shot.\n",
    "\n",
    "---\n",
    "\n",
    "**Why SetFit excels in limited-label regimes**\n",
    "\n",
    "1. **Data amplification via contrastive pairs**\n",
    "\n",
    "   * From each labeled example, SetFit creates positive pairs (e.g. two different augmentations of the same sentence) and negative pairs (across classes), turning 32 labels into hundreds or thousands of pairwise signals.\n",
    "   * That extra signal helps the embedding space separate classes, even when you only have a few “gold” labels.\n",
    "\n",
    "2. **Lightweight classifier**\n",
    "\n",
    "   * Because the embedding model has already been tuned to distinguish your classes, the final classifier can be a simple logistic or MLP—so it needs very few examples to learn decision boundaries.\n",
    "\n",
    "3. **Empirical few-shot strength**\n",
    "\n",
    "   * In benchmarks, SetFit often outperforms standard BERT fine-tuning when you have <100 labels, and it’s much faster to train (no full back-prop through all BERT layers).\n",
    "\n",
    "---\n",
    "\n",
    "**How to plug SetFit into the task**\n",
    "\n",
    "1. **Install** the SetFit library (e.g. via `pip install setfit`).\n",
    "2. **Initialize** a pre-trained checkpoint:\n",
    "\n",
    "   ```python\n",
    "   from setfit import SetFitModel, SetFitTrainer\n",
    "   model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
    "   ```\n",
    "3. **Prepare** your 32 labeled examples as `(text, label)` tuples.\n",
    "4. **Train** the model:\n",
    "\n",
    "   ```python\n",
    "   trainer = SetFitTrainer(\n",
    "       model=model,\n",
    "       train_dataset=my_32_examples,\n",
    "       eval_dataset=my_dev_split,\n",
    "       metric=\"accuracy\",\n",
    "       loss=\"cosine-similarity\",\n",
    "       batch_size=16,\n",
    "       num_iterations=20,          # controls number of contrastive steps\n",
    "       num_epochs=1                # just one pass for the classifier\n",
    "   )\n",
    "   trainer.train()\n",
    "   ```\n",
    "5. **Evaluate** on your held-out data.\n",
    "\n",
    "You’ll have fine-tuned embeddings *and* a classifier head—all with only 32 labels. That makes SetFit not just “considered training,” but *one of the best* training-with-few-labels recipes out there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaca434",
   "metadata": {},
   "source": [
    "# 2. Dataset Augmentation\n",
    "\n",
    "Outline of the intermediate tasks: We want a fully automated pipeline. A good candidate is Easy Data Augmentation (EDA) or back-translation via open‐source MT models.\n",
    "1. Choose Technique(s)\n",
    "   - EDA: random synonym substitution (WordNet or fastText), random swap, insertion, deletion.\n",
    "   - Back-translation: FR → EN → FR and IT → EN → IT using MarianMT or opus-MT.\n",
    "2. Implement & Generate\n",
    "   - For each of the 32 labeled examples, generate k augmented pseudo-examples (e.g. k=5).\n",
    "   - Deduplicate and filter (e.g. reject if new text <50% overlap).\n",
    "3. Merge & Re-split\n",
    "   - Combine original 32 + synthetic N = 32×k examples.\n",
    "   - Re-run the same CV split strategy, ensuring augmented copies of a given original stay in the same fold.\n",
    "4. Re-train BERT\n",
    "   - Exactly the same hyperparams as in (a).\n",
    "   - Track performance uplift vs. the baseline.\n",
    "5. Analysis\n",
    "   - Compare metrics: ΔAccuracy, ΔF1.\n",
    "   - Ablation: EDA vs. back-translation vs. combined.\n",
    "   - Qualitative: inspect a few synthetic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ccf8a",
   "metadata": {},
   "source": [
    "# 3. Zero-Shot Learning with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49577eb6",
   "metadata": {},
   "source": [
    "### Select balanced dataset samples (16 from each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62338af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 32 labeled examples\n"
     ]
    }
   ],
   "source": [
    "def select_balanced_samples(df, n_samples=32):\n",
    "    class_0_samples = df.filter((pl.col('label') == 0) & (pl.col('split') == 'train')).sample(n_samples/2)\n",
    "    class_1_samples = df.filter((pl.col('label') == 1) & (pl.col('split') == 'train')).sample(n_samples/2)\n",
    "\n",
    "    labeled_samples = pl.concat([class_0_samples, class_1_samples])\n",
    "    return labeled_samples\n",
    "\n",
    "labeled_data = select_balanced_samples(df, n_samples=32)\n",
    "print(f\"Selected {len(labeled_data)} labeled examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f400c",
   "metadata": {},
   "source": [
    "### Activate Groq client for LLM API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10085446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq(api_key=groq_api_key)\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbcb58",
   "metadata": {},
   "source": [
    "### Create zero-shot prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7717ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_legal_prompt(case_text):\n",
    "    prompt = f\"\"\"Vous êtes un juriste qui analyse des affaires du Tribunal fédéral suisse. Les textes sont en français. Vous devez déterminer la langue à partir du texte.\n",
    "    En vous basant uniquement sur les faits de l'affaire ci-dessous, déterminez si l'affaire doit être rejetée (0) ou approuvée (1).\n",
    "    \n",
    "    Le rejet (0) signifie que le recours est rejeté\n",
    " L'approbation (1) signifie que le recours est accepté.\n",
    "    \n",
    "    Faits de l'affaire :\n",
    "    {case_text}\n",
    "    \n",
    "    Analysez le cas et répondez par un seul chiffre : 0 pour le rejet ou 1 pour l'approbation.\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def classify_case(case_text):\n",
    "    prompt = create_legal_prompt(case_text)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "    \n",
    "        prediction_text = response.choices[0].message.content.strip() # extract the label from response, look for 0 or 1\n",
    "        if \"0\" in prediction_text:\n",
    "            return 0\n",
    "        elif \"1\" in prediction_text:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 # default majority class\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in API call: {e}\")\n",
    "        return 0 # again majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5804a45",
   "metadata": {},
   "source": [
    "### Process some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d64795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_batch(df, batch_size=10):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.slice(i, min(batch_size, len(df) - i))\n",
    "        \n",
    "        for case in tqdm.tqdm(batch.iter_rows(named=True)):\n",
    "            y_true.append(case['label'])\n",
    "            prediction = classify_case(case['text'])\n",
    "            y_pred.append(prediction)            \n",
    "            #time.sleep(0.5) # avoid API rate limits\n",
    "            \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ddefa",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b81358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying samples from the test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d8fcd4ed4a4115b58617e15cf75b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics calculated for: zero_shot_llm\n",
      "\n",
      "========================================\n",
      "Metrics for zero_shot_llm\n",
      "========================================\n",
      "\n",
      "Accuracy: 70.00%\n",
      "\n",
      "Precision: 0.00%\n",
      "\n",
      "Recall: 0.00%\n",
      "\n",
      "F1 Score: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = french_texts.filter(pl.col('split') == 'test').sample(100)\n",
    "\n",
    "print(\"Classifying samples from the test set...\")\n",
    "y_true, y_pred = process_batch(test_samples)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics.run(y_true, y_pred, f'zero_shot_llm', average='binary')\n",
    "\n",
    "# print results of zero-shot LLM classification\n",
    "metrics.print_results()\n",
    "metrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f7924",
   "metadata": {},
   "source": [
    "## With Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fdc30d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://huggingface.co/google/gemma-7b/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1533\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1450\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1449\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:473\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    468\u001b[39m     message = (\n\u001b[32m    469\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    471\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure your token has the correct permissions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m416\u001b[39m:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: (Request ID: Root=1-684c5b6e-46fbccdc32f4e7be261605bc;4ccfb61b-7f1e-4133-9d87-22932ece0320)\n\n403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\nCannot access content at: https://huggingface.co/google/gemma-7b/resolve/main/config.json.\nMake sure your token has the correct permissions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1648\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1647\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is on.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1652\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhead_call_error\u001b[39;00m\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle/gemma-7b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m model = AutoModelForCausalLM.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mgoogle/gemma-7b\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:970\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    968\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1153\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1151\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1153\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1155\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:595\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    593\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:654\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    650\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    653\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    669\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:543\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[32m    541\u001b[39m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    544\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load the files, and couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find them in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    545\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
      "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b21e380",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://huggingface.co/google/gemma-7b/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1533\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1450\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1449\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:473\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    468\u001b[39m     message = (\n\u001b[32m    469\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    471\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure your token has the correct permissions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m416\u001b[39m:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: (Request ID: Root=1-684c5aed-2628eb1c571482f27709a2f0;b36fa517-deae-4edc-943a-ea9780598d34)\n\n403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..\nCannot access content at: https://huggingface.co/google/gemma-7b/resolve/main/config.json.\nMake sure your token has the correct permissions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:470\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1115\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1114\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1648\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1647\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[32m   1649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is on.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1652\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhead_call_error\u001b[39;00m\n",
      "\u001b[31mLocalEntryNotFoundError\u001b[39m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load model and tokenizer\u001b[39;00m\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mgoogle/gemma-7b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m model = AutoModelForCausalLM.from_pretrained(model_name)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:970\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    968\u001b[39m         config = AutoConfig.for_model(**config_dict)\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m         config = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m config_tokenizer_class = config.tokenizer_class\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoTokenizer\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1153\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1150\u001b[39m trust_remote_code = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtrust_remote_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1151\u001b[39m code_revision = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1153\u001b[39m config_dict, unused_kwargs = \u001b[43mPretrainedConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m has_remote_code = \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1155\u001b[39m has_local_code = \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:595\u001b[39m, in \u001b[36mPretrainedConfig.get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    593\u001b[39m original_kwargs = copy.deepcopy(kwargs)\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m config_dict, kwargs = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\configuration_utils.py:654\u001b[39m, in \u001b[36mPretrainedConfig._get_config_dict\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    650\u001b[39m configuration_file = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_configuration_file\u001b[39m\u001b[33m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    653\u001b[39m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    669\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:312\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    255\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    256\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    257\u001b[39m     **kwargs,\n\u001b[32m    258\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    259\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    261\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\NLP\\adv_nlp_final_assessment\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:543\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[38;5;66;03m# Here we only raise if both flags for missing entry and connection errors are True (because it can be raised\u001b[39;00m\n\u001b[32m    541\u001b[39m     \u001b[38;5;66;03m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    544\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWe couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to load the files, and couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find them in the\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    545\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m cached files.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;66;03m# snapshot_download will not raise EntryNotFoundError, but hf_hub_download can. If this is the case, it will be treated\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# later on anyway and re-raised if needed\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, HTTPError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n",
      "\u001b[31mOSError\u001b[39m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/gemma-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb57e3",
   "metadata": {},
   "source": [
    "# 4. Data Generation with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ad1cc",
   "metadata": {},
   "source": [
    "# 5. Optimal Technique Application"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
