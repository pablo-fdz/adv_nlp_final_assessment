{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 3: State of the Art Comparison (2 points)\n",
    "\n",
    "- **Objective:** Benchmark your model against the SOA with the full dataset now available.\n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. Full Dataset Training (0.25 points):** Incrementally train your model with varying percentages of the full dataset (1%, 10%, 25%, 50%, 75%, and 100%). Record the results.\n",
    "  - **b. Learning Curve (0.25 points):** Plot a learning curve based on the training data percentages.\n",
    "  - **c. Technique Comparison (0.5 points):** Incorporate the techniques tested in Part 2 into your training schema for comparison.\n",
    "  - **d. Methodology Analysis (1 point):** Analyze and compare all methods employed. Discuss the effectiveness and limitations observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from library.utilities import set_seed, sample_balanced_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specific for mac users with M1 chip (That do not have CUDA)\n",
    "# # !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# import torch\n",
    "# print(torch.backends.mps.is_available())      # Is Metal available?\n",
    "# print(torch.backends.mps.is_built()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect if MPS (GPU in Mac) is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch.ones(3, 3).to(device)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42. This ensures reproducibility of results across runs.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Full dataset training: Incrementally train your mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded DataFrame shape: (31094, 9)\n",
      "\n",
      "Loaded DataFrame schema:\n",
      "Schema([('id', Int32), ('year', Int32), ('text', String), ('labels', Int64), ('language', String), ('region', String), ('canton', String), ('legal area', String), ('split', String)])\n",
      "\n",
      "First few rows of the loaded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>year</th><th>text</th><th>labels</th><th>language</th><th>region</th><th>canton</th><th>legal area</th><th>split</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>2000</td><td>&quot;A.- Par contrat d&#x27;entreprise s…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;civil law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>1</td><td>2000</td><td>&quot;A.- Le 12 avril 1995, A._ a su…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>2</td><td>2000</td><td>&quot;A.- En février 1994, M._ a été…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>3</td><td>2000</td><td>&quot;A.- M._ a travaillé en qualité…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>6</td><td>2000</td><td>&quot;A.- Le 29 septembre 1997, X._ …</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Espace Mittelland&quot;</td><td>&quot;ne&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────┬──────┬───────────────────┬────────┬───┬───────────────────┬────────┬───────────────┬───────┐\n",
       "│ id  ┆ year ┆ text              ┆ labels ┆ … ┆ region            ┆ canton ┆ legal area    ┆ split │\n",
       "│ --- ┆ ---  ┆ ---               ┆ ---    ┆   ┆ ---               ┆ ---    ┆ ---           ┆ ---   │\n",
       "│ i32 ┆ i32  ┆ str               ┆ i64    ┆   ┆ str               ┆ str    ┆ str           ┆ str   │\n",
       "╞═════╪══════╪═══════════════════╪════════╪═══╪═══════════════════╪════════╪═══════════════╪═══════╡\n",
       "│ 0   ┆ 2000 ┆ A.- Par contrat   ┆ 0      ┆ … ┆ null              ┆ null   ┆ civil law     ┆ train │\n",
       "│     ┆      ┆ d'entreprise s…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 1   ┆ 2000 ┆ A.- Le 12 avril   ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1995, A._ a su…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 2   ┆ 2000 ┆ A.- En février    ┆ 0      ┆ … ┆ Région lémanique  ┆ ge     ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1994, M._ a été…  ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 3   ┆ 2000 ┆ A.- M._ a         ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ travaillé en      ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ qualité…          ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 6   ┆ 2000 ┆ A.- Le 29         ┆ 0      ┆ … ┆ Espace Mittelland ┆ ne     ┆ penal law     ┆ train │\n",
       "│     ┆      ┆ septembre 1997,   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ X._ …             ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "└─────┴──────┴───────────────────┴────────┴───┴───────────────────┴────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Parquet file\n",
    "df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_combined.parquet')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"\\nLoaded DataFrame shape:\", df.shape)\n",
    "print(\"\\nLoaded DataFrame schema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nFirst few rows of the loaded DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training, validation and test sets\n",
    "train_df = df.filter(pl.col('split') == 'train')\n",
    "val_df = df.filter(pl.col('split') == 'validation')\n",
    "test_df = df.filter(pl.col('split') == 'test')\n",
    "\n",
    "# Delete the original data to free up memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the train, validation and test Parquet files\n",
    "# train_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_train.parquet')\n",
    "# valid_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_valid.parquet')\n",
    "# test_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_test.parquet')\n",
    "\n",
    "# # Display the loaded DataFrames\n",
    "# print(\"\\nTrain DataFrame shape:\", train_df.shape)\n",
    "# print(\"\\nValidation DataFrame shape:\", valid_df.shape)\n",
    "# print(\"\\nTest DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# print(\"\\nTrain DataFrame schema:\")\n",
    "# print(train_df.schema)\n",
    "# print(\"\\nFirst few rows of the train DataFrame:\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: almanach/camembert-base, Max Length: 512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"almanach/camembert-base\"  # Path to the pre-trained model\n",
    "num_labels = 2  # Number of labels for the classification task (in this case, binary classification)\n",
    "max_length = min(int(AutoModel.from_pretrained(model_name).config.max_position_embeddings), 512)  # Maximum length of the input sequences (truncation if larger than this). Set dynamically based on the chosen model.\n",
    "\n",
    "print(f\"Model: {model_name}, Max Length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7/7 [00:00<00:00, 195.56 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 756.32 examples/s]\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/20 : < :, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mincremental_train\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_incremental_training, train_with_percentage\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# # Train all the percentages incrementally:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# summary_df = run_incremental_training(\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     train_df=train_df,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# subsample to not break my mac\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_percentage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_df_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/library/incremental_train/doc.py:70\u001b[0m, in \u001b[0;36mtrain_with_percentage\u001b[0;34m(train_df, valid_df, percentage, model_name, max_length, num_labels, seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m train_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     39\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpart_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcls_fine_tuning_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msan_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercentage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     40\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     57\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     58\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     59\u001b[0m     args\u001b[38;5;241m=\u001b[39mtrain_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)]\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m log_history \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlog_history\n\u001b[1;32m     72\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m [log \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m log_history \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m log]\n",
      "File \u001b[0;32m~/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/venv/lib/python3.9/site-packages/transformers/trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment-1/venv/lib/python3.9/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2561\u001b[0m ):\n\u001b[1;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from library.incremental_train.doc import run_incremental_training, train_with_percentage\n",
    "\n",
    "# Train all the percentages incrementally:\n",
    "summary_df = run_incremental_training(\n",
    "    train_df=train_df,\n",
    "    valid_df=val_df,  \n",
    "    model_name=model_name,\n",
    "    max_length=max_length,\n",
    "    num_labels=num_labels,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(\"\\nFinal summary of results across all percentages:\")\n",
    "display(summary_df)\n",
    "\n",
    "# Or to train specific percentage only:\n",
    "# result = train_with_percentage(train_df, val_df, 1, model_name, max_length, num_labels, seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(summary_df, metric='eval_accuracy'):\n",
    "    \"\"\"\n",
    "    Plots a learning curve for the given metric from the summary DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=metric)\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve: {metric.replace(\"_\", \" \").title()} vs. Training Set Size')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(summary_df['percentage'])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy learning curve\n",
    "plot_learning_curve(summary_df, metric='eval_accuracy')\n",
    "\n",
    "# You can also plot F1, loss, etc.\n",
    "plot_learning_curve(summary_df, metric='eval_f1')\n",
    "plot_learning_curve(summary_df, metric='eval_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Technique Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from library.incremental_train.doc import run_incremental_training\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"almanach/camembert-base\",\n",
    "    \"dascim/juribert-base\",\n",
    "    \"google-bert/bert-base-multilingual-cased\"\n",
    "]\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train each model \n",
    "for model_name in model_names:\n",
    "    print(f\"\\nEntrenando modelo: {model_name}\")\n",
    "    summary_df = run_incremental_training(\n",
    "        train_df=train_df,\n",
    "        valid_df=val_df,\n",
    "        model_name=model_name,\n",
    "        max_length=max_length,\n",
    "        num_labels=num_labels,\n",
    "        seed=seed\n",
    "    )\n",
    "    results[model_name] = summary_df\n",
    "\n",
    "# Graph the learning curves\n",
    "def plot_comparison(results, metric='eval_accuracy'):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for model_name, summary_df in results.items():\n",
    "        plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=model_name.split('/')[-1])\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve Comparison: {metric.replace(\"_\", \" \").title()}')\n",
    "    plt.grid(True)\n",
    "    plt.xticks([1, 10, 25, 50, 75, 100])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Comparison of accuracy and F1 scores\n",
    "plot_comparison(results, metric='eval_accuracy')\n",
    "plot_comparison(results, metric='eval_f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodology Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
