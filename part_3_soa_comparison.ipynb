{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Instructions and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Instructions. Part 3: State of the Art Comparison (2 points)\n",
    "\n",
    "- **Objective:** Benchmark your model against the SOA with the full dataset now available.\n",
    "\n",
    "- **Tasks:**\n",
    "  - **a. Full Dataset Training (0.25 points):** Incrementally train your model with varying percentages of the full dataset (1%, 10%, 25%, 50%, 75%, and 100%). Record the results.\n",
    "  - **b. Learning Curve (0.25 points):** Plot a learning curve based on the training data percentages.\n",
    "  - **c. Technique Comparison (0.5 points):** Incorporate the techniques tested in Part 2 into your training schema for comparison.\n",
    "  - **d. Methodology Analysis (1 point):** Analyze and compare all methods employed. Discuss the effectiveness and limitations observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading WordNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/masha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/masha/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Open Multilingual WordNet...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from library.utilities import set_seed, sample_balanced_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specific for mac users with M1 chip (That do not have CUDA)\n",
    "# # !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# import torch\n",
    "# print(torch.backends.mps.is_available())      # Is Metal available?\n",
    "# print(torch.backends.mps.is_built()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect if MPS (GPU in Mac) is available\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch.ones(3, 3).to(device)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42. This ensures reproducibility of results across runs.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Full dataset training: Incrementally train your mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded DataFrame shape: (31094, 9)\n",
      "\n",
      "Loaded DataFrame schema:\n",
      "Schema({'id': Int32, 'year': Int32, 'text': String, 'labels': Int64, 'language': String, 'region': String, 'canton': String, 'legal area': String, 'split': String})\n",
      "\n",
      "First few rows of the loaded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>year</th><th>text</th><th>labels</th><th>language</th><th>region</th><th>canton</th><th>legal area</th><th>split</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>2000</td><td>&quot;A.- Par contrat d&#x27;entreprise s…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;civil law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>1</td><td>2000</td><td>&quot;A.- Le 12 avril 1995, A._ a su…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>2</td><td>2000</td><td>&quot;A.- En février 1994, M._ a été…</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Région lémanique&quot;</td><td>&quot;ge&quot;</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>3</td><td>2000</td><td>&quot;A.- M._ a travaillé en qualité…</td><td>0</td><td>&quot;fr&quot;</td><td>null</td><td>null</td><td>&quot;insurance law&quot;</td><td>&quot;train&quot;</td></tr><tr><td>6</td><td>2000</td><td>&quot;A.- Le 29 septembre 1997, X._ …</td><td>0</td><td>&quot;fr&quot;</td><td>&quot;Espace Mittelland&quot;</td><td>&quot;ne&quot;</td><td>&quot;penal law&quot;</td><td>&quot;train&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌─────┬──────┬───────────────────┬────────┬───┬───────────────────┬────────┬───────────────┬───────┐\n",
       "│ id  ┆ year ┆ text              ┆ labels ┆ … ┆ region            ┆ canton ┆ legal area    ┆ split │\n",
       "│ --- ┆ ---  ┆ ---               ┆ ---    ┆   ┆ ---               ┆ ---    ┆ ---           ┆ ---   │\n",
       "│ i32 ┆ i32  ┆ str               ┆ i64    ┆   ┆ str               ┆ str    ┆ str           ┆ str   │\n",
       "╞═════╪══════╪═══════════════════╪════════╪═══╪═══════════════════╪════════╪═══════════════╪═══════╡\n",
       "│ 0   ┆ 2000 ┆ A.- Par contrat   ┆ 0      ┆ … ┆ null              ┆ null   ┆ civil law     ┆ train │\n",
       "│     ┆      ┆ d'entreprise s…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 1   ┆ 2000 ┆ A.- Le 12 avril   ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1995, A._ a su…   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 2   ┆ 2000 ┆ A.- En février    ┆ 0      ┆ … ┆ Région lémanique  ┆ ge     ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ 1994, M._ a été…  ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 3   ┆ 2000 ┆ A.- M._ a         ┆ 0      ┆ … ┆ null              ┆ null   ┆ insurance law ┆ train │\n",
       "│     ┆      ┆ travaillé en      ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ qualité…          ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│ 6   ┆ 2000 ┆ A.- Le 29         ┆ 0      ┆ … ┆ Espace Mittelland ┆ ne     ┆ penal law     ┆ train │\n",
       "│     ┆      ┆ septembre 1997,   ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "│     ┆      ┆ X._ …             ┆        ┆   ┆                   ┆        ┆               ┆       │\n",
       "└─────┴──────┴───────────────────┴────────┴───┴───────────────────┴────────┴───────────────┴───────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned Parquet file\n",
    "df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_combined.parquet')\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(\"\\nLoaded DataFrame shape:\", df.shape)\n",
    "print(\"\\nLoaded DataFrame schema:\")\n",
    "print(df.schema)\n",
    "print(\"\\nFirst few rows of the loaded DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training, validation and test sets\n",
    "train_df = df.filter(pl.col('split') == 'train')\n",
    "val_df = df.filter(pl.col('split') == 'validation')\n",
    "test_df = df.filter(pl.col('split') == 'test')\n",
    "\n",
    "# Delete the original data to free up memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the train, validation and test Parquet files\n",
    "# train_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_train.parquet')\n",
    "# valid_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_valid.parquet')\n",
    "# test_df = pl.read_parquet('data/FRENCH_swiss_judgment_prediction_test.parquet')\n",
    "\n",
    "# # Display the loaded DataFrames\n",
    "# print(\"\\nTrain DataFrame shape:\", train_df.shape)\n",
    "# print(\"\\nValidation DataFrame shape:\", valid_df.shape)\n",
    "# print(\"\\nTest DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# print(\"\\nTrain DataFrame schema:\")\n",
    "# print(train_df.schema)\n",
    "# print(\"\\nFirst few rows of the train DataFrame:\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: almanach/camembert-base, Max Length: 512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"almanach/camembert-base\"  # Path to the pre-trained model\n",
    "num_labels = 2  # Number of labels for the classification task (in this case, binary classification)\n",
    "max_length = min(int(AutoModel.from_pretrained(model_name).config.max_position_embeddings), 512)  # Maximum length of the input sequences (truncation if larger than this). Set dynamically based on the chosen model.\n",
    "\n",
    "print(f\"Model: {model_name}, Max Length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 1% of the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment/env/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n",
      "Map: 100%|██████████| 211/211 [00:00<00:00, 658.20 examples/s]\n",
      "Map: 100%|██████████| 3095/3095 [00:02<00:00, 1119.33 examples/s]\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at almanach/camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/masha/Desktop/master/3 trim/Advanced NLP/adv_nlp_final_assessment/env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:685: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from library.incremental_train.doc import run_incremental_training, train_with_percentage\n",
    "\n",
    "# Para entrenamiento incremental:\n",
    "summary_df = run_incremental_training(\n",
    "    train_df=train_df,\n",
    "    valid_df=val_df,  # asegúrate de que tu variable de validación se llame así\n",
    "    model_name=model_name,\n",
    "    max_length=max_length,\n",
    "    num_labels=num_labels,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print(\"\\nFinal summary of results across all percentages:\")\n",
    "display(summary_df)\n",
    "\n",
    "# Si quieres usar train_with_percentage directamente:\n",
    "# result = train_with_percentage(train_df, valid_df, 10, model_name, max_length, num_labels, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(summary_df, metric='eval_accuracy'):\n",
    "    \"\"\"\n",
    "    Plots a learning curve for the given metric from the summary DataFrame.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(summary_df['percentage'], summary_df[metric], marker='o', label=metric)\n",
    "    plt.xlabel('Percentage of Training Data Used')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'Learning Curve: {metric.replace(\"_\", \" \").title()} vs. Training Set Size')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(summary_df['percentage'])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy learning curve\n",
    "plot_learning_curve(summary_df, metric='eval_accuracy')\n",
    "\n",
    "# You can also plot F1, loss, etc.\n",
    "plot_learning_curve(summary_df, metric='eval_f1')\n",
    "plot_learning_curve(summary_df, metric='eval_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Technique Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodology Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
